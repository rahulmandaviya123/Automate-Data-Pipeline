# Automate Data Pipeline in Python

## ğŸ“Œ Project Overview
This project demonstrates how to build an **automated data pipeline in Python**.  
It covers file handling, data processing, and archiving to streamline workflow.

## ğŸš€ Features
- Reads and processes CSV files
- Handles processed files automatically
- Archives old files
- Fully automated workflow

## ğŸ› ï¸ Tech Stack
- Python 3.x
- Pandas
- OS, Glob, Shutil

## ğŸ“‚ Project Structure
```
Automate-Data-Pipeline/
â”‚â”€â”€ notebooks/                     # Jupyter notebooks
â”‚â”€â”€ src/                           # Source Python scripts
â”‚â”€â”€ data/                          # Sample input/output data
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .gitignore
```

## âš™ï¸ Installation
1. Clone this repo:
   ```bash
   git clone https://github.com/your-username/automate-data-pipeline.git
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## â–¶ï¸ Usage
Run the pipeline:
```bash
python src/pipeline.py
```

Or explore the Jupyter notebook in:
```
notebooks/Automate_Data_pipeline-2.ipynb
```

## ğŸ“Œ Next Steps
- Add scheduling with `cron` or `Airflow`
- Extend to handle more file types
- Add cloud storage integration
